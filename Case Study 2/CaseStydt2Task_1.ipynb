{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u10b3WsmSvYX"
      },
      "source": [
        "# Case Stydy 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrgJN_LxS9D1"
      },
      "source": [
        "**Task 1: Data Extraction and Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fcq4aK9qDAon"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv(\"/content/characters.csv\")\n",
        "test_data = pd.read_csv(\"/content/characters-test.csv\")\n",
        "\n",
        "# Extract labels and images\n",
        "train_labels = train_data.iloc[:, 0].values\n",
        "train_images = train_data.iloc[:, 1:].values.reshape(-1, 1, 28, 28).astype('float32') / 255.0\n",
        "\n",
        "test_labels = test_data.iloc[:, 0].values\n",
        "test_images = test_data.iloc[:, 1:].values.reshape(-1, 1, 28, 28).astype('float32') / 255.0\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgugcupBDfuX"
      },
      "outputs": [],
      "source": [
        "label_to_char = {}\n",
        "with open(\"/content/mapping.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        num, ascii_code = line.split()\n",
        "        label_to_char[int(num)] = chr(int(ascii_code))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xar4D-m8Dkdl"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        # Use a dummy tensor to calculate the output size dynamically\n",
        "        dummy_input = torch.zeros(1, 1, 28, 28)\n",
        "        dummy_output = self.pool(F.relu(self.conv2(self.pool(F.relu(self.conv1(dummy_input))))))\n",
        "        self.flatten_size = dummy_output.numel()\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
        "        self.fc2 = nn.Linear(128, len(label_to_char))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i72WhyUDn_t",
        "outputId": "26cf8f67-8eb4-470b-a255-39e7583e7335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Validation Accuracy: 83.34%\n",
            "Epoch 2, Validation Accuracy: 85.24%\n",
            "Epoch 3, Validation Accuracy: 86.32%\n",
            "Epoch 4, Validation Accuracy: 86.66%\n",
            "Epoch 5, Validation Accuracy: 86.80%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "val_dataset = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "# Define the model, loss, and optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):  # Train for 5 epochs\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Epoch {epoch+1}, Validation Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8VL6vNwMAxo",
        "outputId": "2a3f7f14-1d44-4697-9c85-b5d745abd7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN model saved successfully!\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"cnn_model.pth\")\n",
        "print(\"CNN model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrBPXcTxhc2h"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Assuming test_images and test_labels are prepared and normalized\n",
        "# Convert test_images and test_labels to PyTorch tensors\n",
        "test_images_tensor = torch.tensor(test_images).float()\n",
        "test_labels_tensor = torch.tensor(test_labels).long()\n",
        "\n",
        "# Create a TensorDataset\n",
        "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
        "\n",
        "# Create the test DataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEIrEFYP3jmv",
        "outputId": "9ca9d506-5e0c-4f73-c16c-209d7f2e71a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJqhlvJ3YvXw",
        "outputId": "ef9c459e-8d30-498d-c1d3-8632338a493f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the CNN model: 86.22%\n"
          ]
        }
      ],
      "source": [
        "# Move the model to the device (GPU in this case)\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy of the CNN model: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijaGwzJTh1fs",
        "outputId": "4ed66cdf-9f41-497e-ce8e-cc77109252dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reconstructed Sentence 1: e9Q9XEA3CG72GGR68SrT84ZeFeXb9eLSFnCKQC1bbqN35nP1EGVqLQHqSYZ0eXGX\n",
            "Reconstructed Sentence 2: 23qIadQSZeNEK3ZrHSXCWVBDfTGWQD1Cg5hHd4BJBOBAArf4URb4P88GY3dA1QdK\n",
            "Reconstructed Sentence 3: ePUTBd5QhFDAXC5PWa0CJ9CAD9YEtNKFWZq5M4KU1SZ6XtASPQTQ1E9KDQ43fKTt\n",
            "Reconstructed Sentence 4: L0d14MD3O5t6AGPBfASSXIPHTK06d5Id4nhCQ5AhL6eACOa09I9Sr4P2hTgDU92N\n",
            "Reconstructed Sentence 5: JH8AX2FYnSFYa3GatAIRRU8N2dFfBH5B2PKNXSS8FaBdN74L815ZRJZLKKD7qM2F\n"
          ]
        }
      ],
      "source": [
        "# Ensure the model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# Decode predictions into characters\n",
        "reconstructed_sentences = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move images and labels to the same device as the model\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Perform the forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Decode predictions\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        characters = [label_to_char[label.item()] for label in predicted]\n",
        "        reconstructed_sentences.append(\"\".join(characters))\n",
        "\n",
        "# Print some example sentences\n",
        "for i, sentence in enumerate(reconstructed_sentences[:5]):\n",
        "    print(f\"Reconstructed Sentence {i+1}: {sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq89DXHHkZMG",
        "outputId": "a7fbb67d-80f7-44d6-92de-c7b873240975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CNN Performance ===\n",
            "Accuracy : 0.8622\n",
            "Precision: 0.8657\n",
            "Recall   : 0.8622\n",
            "F1-Score : 0.8600\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y_true = []  # True labels\n",
        "y_pred = []  # Predicted labels\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move images and labels to the GPU (or the device where the model is located)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Move predictions and labels to CPU for sklearn compatibility\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate metrics\n",
        "precision = precision_score(y_true, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_true, y_pred, average=\"macro\")\n",
        "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "accuracy = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred)) / len(y_true)\n",
        "\n",
        "# Print metrics\n",
        "print(\"=== CNN Performance ===\")\n",
        "print(f\"Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1-Score : {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZlOkTG2lN-J",
        "outputId": "c85b1350-3f79-4e77-87a5-ba8b677063f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 71.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, len(label_to_char))\n",
        "resnet18 = resnet18.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35gX7fLAlUKQ",
        "outputId": "8464403a-423a-4842-cea3-9e702ddfc3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1, Batch 100] Loss: 2.3428\n",
            "[Epoch 1, Batch 200] Loss: 0.9029\n",
            "[Epoch 1, Batch 300] Loss: 0.6482\n",
            "[Epoch 1, Batch 400] Loss: 0.5874\n",
            "[Epoch 1, Batch 500] Loss: 0.5209\n",
            "[Epoch 1, Batch 600] Loss: 0.4911\n",
            "[Epoch 1, Batch 700] Loss: 0.4730\n",
            "[Epoch 1, Batch 800] Loss: 0.4677\n",
            "[Epoch 1, Batch 900] Loss: 0.4371\n",
            "[Epoch 1, Batch 1000] Loss: 0.4453\n",
            "[Epoch 1, Batch 1100] Loss: 0.4340\n",
            "[Epoch 1, Batch 1200] Loss: 0.4202\n",
            "[Epoch 1, Batch 1300] Loss: 0.4138\n",
            "[Epoch 1, Batch 1400] Loss: 0.4126\n",
            "Epoch 1: Validation Accuracy = 87.42%\n",
            "[Epoch 2, Batch 100] Loss: 0.3509\n",
            "[Epoch 2, Batch 200] Loss: 0.3606\n",
            "[Epoch 2, Batch 300] Loss: 0.3580\n",
            "[Epoch 2, Batch 400] Loss: 0.3482\n",
            "[Epoch 2, Batch 500] Loss: 0.3661\n",
            "[Epoch 2, Batch 600] Loss: 0.3506\n",
            "[Epoch 2, Batch 700] Loss: 0.3602\n",
            "[Epoch 2, Batch 800] Loss: 0.3455\n",
            "[Epoch 2, Batch 900] Loss: 0.3686\n",
            "[Epoch 2, Batch 1000] Loss: 0.3547\n",
            "[Epoch 2, Batch 1100] Loss: 0.3535\n",
            "[Epoch 2, Batch 1200] Loss: 0.3700\n",
            "[Epoch 2, Batch 1300] Loss: 0.3255\n",
            "[Epoch 2, Batch 1400] Loss: 0.3424\n",
            "Epoch 2: Validation Accuracy = 88.14%\n",
            "[Epoch 3, Batch 100] Loss: 0.2938\n",
            "[Epoch 3, Batch 200] Loss: 0.3126\n",
            "[Epoch 3, Batch 300] Loss: 0.2904\n",
            "[Epoch 3, Batch 400] Loss: 0.2998\n",
            "[Epoch 3, Batch 500] Loss: 0.2876\n",
            "[Epoch 3, Batch 600] Loss: 0.3209\n",
            "[Epoch 3, Batch 700] Loss: 0.3030\n",
            "[Epoch 3, Batch 800] Loss: 0.3165\n",
            "[Epoch 3, Batch 900] Loss: 0.2916\n",
            "[Epoch 3, Batch 1000] Loss: 0.2939\n",
            "[Epoch 3, Batch 1100] Loss: 0.3019\n",
            "[Epoch 3, Batch 1200] Loss: 0.3413\n",
            "[Epoch 3, Batch 1300] Loss: 0.3327\n",
            "[Epoch 3, Batch 1400] Loss: 0.3081\n",
            "Epoch 3: Validation Accuracy = 88.16%\n",
            "[Epoch 4, Batch 100] Loss: 0.2670\n",
            "[Epoch 4, Batch 200] Loss: 0.2726\n",
            "[Epoch 4, Batch 300] Loss: 0.2753\n",
            "[Epoch 4, Batch 400] Loss: 0.2761\n",
            "[Epoch 4, Batch 500] Loss: 0.2722\n",
            "[Epoch 4, Batch 600] Loss: 0.2781\n",
            "[Epoch 4, Batch 700] Loss: 0.2835\n",
            "[Epoch 4, Batch 800] Loss: 0.2849\n",
            "[Epoch 4, Batch 900] Loss: 0.2787\n",
            "[Epoch 4, Batch 1000] Loss: 0.2878\n",
            "[Epoch 4, Batch 1100] Loss: 0.2915\n",
            "[Epoch 4, Batch 1200] Loss: 0.2897\n",
            "[Epoch 4, Batch 1300] Loss: 0.2654\n",
            "[Epoch 4, Batch 1400] Loss: 0.2837\n",
            "Epoch 4: Validation Accuracy = 88.91%\n",
            "[Epoch 5, Batch 100] Loss: 0.2530\n",
            "[Epoch 5, Batch 200] Loss: 0.2426\n",
            "[Epoch 5, Batch 300] Loss: 0.2534\n",
            "[Epoch 5, Batch 400] Loss: 0.2549\n",
            "[Epoch 5, Batch 500] Loss: 0.2497\n",
            "[Epoch 5, Batch 600] Loss: 0.2699\n",
            "[Epoch 5, Batch 700] Loss: 0.2685\n",
            "[Epoch 5, Batch 800] Loss: 0.2523\n",
            "[Epoch 5, Batch 900] Loss: 0.2622\n",
            "[Epoch 5, Batch 1000] Loss: 0.2558\n",
            "[Epoch 5, Batch 1100] Loss: 0.2656\n",
            "[Epoch 5, Batch 1200] Loss: 0.2629\n",
            "[Epoch 5, Batch 1300] Loss: 0.2557\n",
            "[Epoch 5, Batch 1400] Loss: 0.2811\n",
            "Epoch 5: Validation Accuracy = 88.70%\n",
            "Training Completed!\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Load Pretrained ResNet-18\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "num_classes = len(label_to_char)\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
        "\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "optimizer = optim.Adam(resnet18.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):  # Train for 5 epochs\n",
        "    resnet18.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet18(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print progress every 100 mini-batches\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"[Epoch {epoch+1}, Batch {i+1}] Loss: {running_loss / 100:.4f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Validation Step\n",
        "    resnet18.eval()\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "            outputs = resnet18(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    print(f\"Epoch {epoch+1}: Validation Accuracy = {val_accuracy:.2f}%\")\n",
        "\n",
        "print(\"Training Completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUIhhxeu7CYB",
        "outputId": "7ff1d1bd-6c78-4d1b-8ae6-e7e44bb075e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ResNet-18 Model Performance ===\n",
            "Accuracy: 0.8856\n",
            "Precision: 0.8902\n",
            "Recall   : 0.8856\n",
            "F1-Score: 0.8843\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate ResNet-18 on the test set\n",
        "resnet18.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "        outputs = resnet18(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred)) / len(y_true)\n",
        "precision = precision_score(y_true, y_pred, average=\"macro\")\n",
        "recall = recall_score(y_true, y_pred, average=\"macro\")\n",
        "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "print(\"=== ResNet-18 Model Performance ===\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2buasGV8Pgx",
        "outputId": "35ccab4b-9771-4e46-9bd1-bfccce9c8c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Model Comparison ===\n",
            "CNN Model:\n",
            "- Accuracy: 0.8622\n",
            "- Precision: 0.8657\n",
            "- Recall   : 0.8622\n",
            "- F1-Score: 0.8600\n",
            "\n",
            "ResNet-18 Model:\n",
            "- Accuracy: 0.8856\n",
            "- Precision: 0.8902\n",
            "- Recall   : 0.8856\n",
            "- F1-Score: 0.8843\n",
            "\n",
            "=== Example Reconstructed Sentences ===\n",
            "CNN Model:\n",
            "Sentence 1: e9Q9XEA3CG72GGR68SrT84ZeFeXb9eLSFnCKQC1bbqN35nP1EGVqLQHqSYZ0eXGX\n",
            "Sentence 2: 23qIadQSZeNEK3ZrHSXCWVBDfTGWQD1Cg5hHd4BJBOBAArf4URb4P88GY3dA1QdK\n",
            "Sentence 3: ePUTBd5QhFDAXC5PWa0CJ9CAD9YEtNKFWZq5M4KU1SZ6XtASPQTQ1E9KDQ43fKTt\n",
            "Sentence 4: L0d14MD3O5t6AGPBfASSXIPHTK06d5Id4nhCQ5AhL6eACOa09I9Sr4P2hTgDU92N\n",
            "Sentence 5: JH8AX2FYnSFYa3GatAIRRU8N2dFfBH5B2PKNXSS8FaBdN74L815ZRJZLKKD7qM2F\n",
            "\n",
            "ResNet-18 Model:\n",
            "Sentence 1: e9QqXEB3LG72GGR6qSrT84ZeFeXb9CLSfnCKQC1bbqN35nP1E6VgLQH9SYZ0eXFX\n",
            "Sentence 2: 23qIadQSZeNfX3ZrHSXCWV8DfTGWQDLCq5hHdYBJB0BAAnf4URb4P88GY3dA1QdK\n",
            "Sentence 3: ePUTBd5QhfDAXC5P6a0CJ9CAD9YEtNKfWZq5M4KUIS26XtASPQTQ1E9KDQ43fKTt\n",
            "Sentence 4: L0d1HMD305t6AGPBfASSXIPHTK06d5Id4nhCQ5AhL6eAC0n09I9SrYP2hTgDU92N\n",
            "Sentence 5: JH8AX2FYnSFYa3GatAIRRU8N2dfFBH5B2PhNXSS8FaBdN74I8L5ZRJ2LKKD7qM2f\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(model, data_loader, label_to_char, device):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    reconstructed_sentences = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            if isinstance(model, models.ResNet):\n",
        "                images = images.repeat(1, 3, 1, 1)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Decode predictions into characters\n",
        "            characters = [label_to_char[label.item()] for label in predicted]\n",
        "            reconstructed_sentences.append(\"\".join(characters))\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred)) / len(y_true)\n",
        "    precision = precision_score(y_true, y_pred, average=\"macro\")\n",
        "    recall = recall_score(y_true, y_pred, average=\"macro\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "    return accuracy, precision, recall, f1, reconstructed_sentences\n",
        "\n",
        "# Evaluate CNN Model\n",
        "cnn_accuracy, cnn_precision, cnn_recall, cnn_f1, cnn_sentences = evaluate_model(\n",
        "    model, test_loader, label_to_char, device\n",
        ")\n",
        "\n",
        "# Evaluate ResNet-18 Model\n",
        "resnet_accuracy, resnet_precision, resnet_recall, resnet_f1, resnet_sentences = evaluate_model(\n",
        "    resnet18, test_loader, label_to_char, device\n",
        ")\n",
        "\n",
        "# Print Comparison Table\n",
        "print(\"=== Model Comparison ===\")\n",
        "print(\"CNN Model:\")\n",
        "print(f\"- Accuracy: {cnn_accuracy:.4f}\")\n",
        "print(f\"- Precision: {cnn_precision:.4f}\")\n",
        "print(f\"- Recall   : {cnn_recall:.4f}\")\n",
        "print(f\"- F1-Score: {cnn_f1:.4f}\")\n",
        "print(\"\\nResNet-18 Model:\")\n",
        "print(f\"- Accuracy: {resnet_accuracy:.4f}\")\n",
        "print(f\"- Precision: {resnet_precision:.4f}\")\n",
        "print(f\"- Recall   : {resnet_recall:.4f}\")\n",
        "print(f\"- F1-Score: {resnet_f1:.4f}\")\n",
        "\n",
        "# Print Example Reconstructed Sentences\n",
        "print(\"\\n=== Example Reconstructed Sentences ===\")\n",
        "print(\"CNN Model:\")\n",
        "for i, sentence in enumerate(cnn_sentences[:5]):\n",
        "    print(f\"Sentence {i+1}: {sentence}\")\n",
        "\n",
        "print(\"\\nResNet-18 Model:\")\n",
        "for i, sentence in enumerate(resnet_sentences[:5]):\n",
        "    print(f\"Sentence {i+1}: {sentence}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
