{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6lK1kjnLtjk"
      },
      "source": [
        "# Task 2: Subjectivity Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2suK-9LDP9-",
        "outputId": "a9ca54f0-3b68-4bcd-8653-4f80662986ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZCIKVhrNeMj",
        "outputId": "ea684f7f-96b6-4572-e8da-6161827b5c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            sentence_id  \\\n",
            "0  b9e1635a-72aa-467f-86d6-f56ef09f62c3   \n",
            "1  f99b5143-70d2-494a-a2f5-c68f10d09d0a   \n",
            "2  4076639c-aa56-4202-ae0f-9d9217f8da68   \n",
            "3  b057c366-698e-419d-a284-9b16d835c64e   \n",
            "4  a5a9645e-7850-41ba-90a2-5def725cd5b8   \n",
            "\n",
            "                                            sentence label  solved_conflict  \n",
            "0  Gone are the days when they led the world in r...  SUBJ             True  \n",
            "1  The trend is expected to reverse as soon as ne...   OBJ            False  \n",
            "2             But there is the specious point again.   OBJ            False  \n",
            "3  He added he wouldn’t be surprised to see a new...   OBJ            False  \n",
            "4  Not less government, you see; the same amount ...  SUBJ            False  \n",
            "                            sentence_id  \\\n",
            "0  8745d4da-91c9-4538-acee-b0e7b1c413fd   \n",
            "1  43de04ad-d0ac-4852-9b4e-cf0bca066188   \n",
            "2  e00b66ee-720a-47e3-a0fb-0e2445b89af6   \n",
            "3  0b95d635-f821-45dd-9f33-b05d63629195   \n",
            "4  5ba3117b-3ef9-4815-acb4-a263d3c816bc   \n",
            "\n",
            "                                            sentence label  \n",
            "0  Who will redistribute the hoarded wealth that ...  SUBJ  \n",
            "1  What we don’t need is the indiscriminate influ...  SUBJ  \n",
            "2  The Social Distance Between Us shows every sig...   OBJ  \n",
            "3  History shows that McCarthy and McConnell, lik...   OBJ  \n",
            "4  So while it’s not hard to reach a banal point ...  SUBJ  \n",
            "Index(['sentence_id', 'sentence', 'label', 'solved_conflict'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv(\"train_en.tsv\", sep=\"\\t\")\n",
        "test_data = pd.read_csv(\"test_en_gold.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Inspect the data\n",
        "print(train_data.head())\n",
        "print(test_data.head())\n",
        "print(train_data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_gM_AMuzOQr0"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_data(data, tokenizer, max_len=128):\n",
        "    inputs = tokenizer(\n",
        "        list(data[\"sentence\"]),\n",
        "        max_length=max_len,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    labels = torch.tensor(data[\"label\"].values)\n",
        "    return inputs, labels\n",
        "\n",
        "# Preprocess training and testing data\n",
        "train_inputs, train_labels = preprocess_data(train_data, tokenizer)\n",
        "test_inputs, test_labels = preprocess_data(test_data, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qM5MAhGMR2Kh"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_data[\"label\"] = label_encoder.fit_transform(train_data[\"label\"])\n",
        "test_data[\"label\"] = label_encoder.transform(test_data[\"label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loGjO8o6R4wf",
        "outputId": "2e989b1e-ae61-41fa-9501-84742b18077e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_id        0\n",
            "sentence           0\n",
            "label              0\n",
            "solved_conflict    0\n",
            "dtype: int64\n",
            "sentence_id    0\n",
            "sentence       0\n",
            "label          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_data.isnull().sum())\n",
        "print(test_data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O99hAI1nR8yB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SubjectivityDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len):\n",
        "        self.texts = data[\"sentence\"].values\n",
        "        self.labels = data[\"label\"].values\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        inputs = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p8hn77trR9Jv"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = SubjectivityDataset(train_data, tokenizer, max_len=128)\n",
        "test_dataset = SubjectivityDataset(test_data, tokenizer, max_len=128)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rKFwrJ9TSo62"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.3):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, (hidden, _) = self.lstm(embedded)\n",
        "        hidden = self.dropout(hidden[-1])\n",
        "        return self.fc(hidden)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p6xlvjjSze1",
        "outputId": "f4be1a39-c997-4802-cfaa-73a7ca81d9f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 34.1264, Accuracy: 0.6410\n",
            "Epoch 2/5, Loss: 34.0484, Accuracy: 0.6410\n",
            "Epoch 3/5, Loss: 34.0725, Accuracy: 0.6410\n",
            "Epoch 4/5, Loss: 34.0623, Accuracy: 0.6410\n",
            "Epoch 5/5, Loss: 33.9617, Accuracy: 0.6410\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Training Loop with Accuracy Evaluation\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    lstm_model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = lstm_model(input_ids)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Store predictions and labels for accuracy calculation\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkIUBF38TDSK",
        "outputId": "cff1fd55-ecf6-4afe-e78d-88d193b8d3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================\n",
            "LSTM Model Performance Metrics:\n",
            "========================================\n",
            "Metric          Score     \n",
            "----------------------------------------\n",
            "Accuracy        0.4774\n",
            "Precision       0.2387\n",
            "Recall          0.5000\n",
            "F1-Score        0.3231\n",
            "========================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "lstm_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "        outputs = lstm_model(input_ids)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "# Print Metrics in a Clear Format\n",
        "print(\"=\"*40)\n",
        "print(\"LSTM Model Performance Metrics:\")\n",
        "print(\"=\"*40)\n",
        "print(f\"{'Metric':<15} {'Score':<10}\")\n",
        "print(\"-\"*40)\n",
        "print(f\"{'Accuracy':<15} {accuracy:.4f}\")\n",
        "print(f\"{'Precision':<15} {precision:.4f}\")\n",
        "print(f\"{'Recall':<15} {recall:.4f}\")\n",
        "print(f\"{'F1-Score':<15} {f1:.4f}\")\n",
        "print(\"=\"*40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoMlBqg6VQYD"
      },
      "source": [
        "**Transfer Learning with Pretrained Transformers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "0ff92414fe694e9f8d1fff6e88dfc713",
            "3b46e3a5703946e0bc12f6cb0781b3ec",
            "edc3d56d9f444812b6bceb6c9e539d1a",
            "56df240df2024ed28d98e7cafab2fb33",
            "d7d3fcb967d145b69907fb91a5af448d",
            "0a1e5a13c7ff473dbf68c054211a05a7",
            "67bc9e3f704641f9be0202c0bc7cba48",
            "0820ebdf1a494e5b9e177966d5994fc3",
            "47b2d8358189451fb5395ec741e55f4f",
            "550de3a1155f465fbb150021ada72d25",
            "8accfd9045e54343910e52537419726b"
          ]
        },
        "id": "CS5ryLC9VSZB",
        "outputId": "84502d0c-7c72-4645-f948-a6d1f99a3a10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ff92414fe694e9f8d1fff6e88dfc713",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VlmFrXq7YxFR"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = AdamW(bert_model.parameters(), lr=2e-5)\n",
        "\n",
        "# Define Learning Rate Scheduler\n",
        "num_training_steps = len(train_loader) * epochs\n",
        "scheduler = get_scheduler(\n",
        "    \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz2Lim8tYztZ",
        "outputId": "188a8b6c-25c2-418f-fbc5-fb0953f713eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.3809, Accuracy: 0.7325\n",
            "Epoch 2/5, Loss: 0.4171, Accuracy: 0.7325\n",
            "Epoch 3/5, Loss: 0.4158, Accuracy: 0.7325\n",
            "Epoch 4/5, Loss: 0.3599, Accuracy: 0.7325\n",
            "Epoch 5/5, Loss: 0.3990, Accuracy: 0.7325\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "bert_model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move data to the GPU\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = bert_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Evaluate accuracy on the test/validation set after the epoch\n",
        "    bert_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Switch back to training mode\n",
        "    bert_model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNzZS-hJaJhj",
        "outputId": "5b9500a2-c460-4a46-8793-0b85bb5c616c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT Model Performance:\n",
            "Accuracy: 0.7325 \n",
            "Precision: 0.7584 \n",
            "Recall: 0.7392 \n",
            "F1-Score: 0.7289\n"
          ]
        }
      ],
      "source": [
        "bert_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "print(f\"BERT Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f} \\nPrecision: {precision:.4f} \\nRecall: {recall:.4f} \\nF1-Score: {f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0820ebdf1a494e5b9e177966d5994fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1e5a13c7ff473dbf68c054211a05a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ff92414fe694e9f8d1fff6e88dfc713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b46e3a5703946e0bc12f6cb0781b3ec",
              "IPY_MODEL_edc3d56d9f444812b6bceb6c9e539d1a",
              "IPY_MODEL_56df240df2024ed28d98e7cafab2fb33"
            ],
            "layout": "IPY_MODEL_d7d3fcb967d145b69907fb91a5af448d"
          }
        },
        "3b46e3a5703946e0bc12f6cb0781b3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a1e5a13c7ff473dbf68c054211a05a7",
            "placeholder": "​",
            "style": "IPY_MODEL_67bc9e3f704641f9be0202c0bc7cba48",
            "value": "model.safetensors: 100%"
          }
        },
        "47b2d8358189451fb5395ec741e55f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "550de3a1155f465fbb150021ada72d25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56df240df2024ed28d98e7cafab2fb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550de3a1155f465fbb150021ada72d25",
            "placeholder": "​",
            "style": "IPY_MODEL_8accfd9045e54343910e52537419726b",
            "value": " 440M/440M [00:05&lt;00:00, 79.0MB/s]"
          }
        },
        "67bc9e3f704641f9be0202c0bc7cba48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8accfd9045e54343910e52537419726b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d3fcb967d145b69907fb91a5af448d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc3d56d9f444812b6bceb6c9e539d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0820ebdf1a494e5b9e177966d5994fc3",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47b2d8358189451fb5395ec741e55f4f",
            "value": 440449768
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
